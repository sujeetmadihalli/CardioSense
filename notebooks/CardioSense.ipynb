{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Predictive model - CardioSense\n",
        "###A Resting Heart Rate Prediction Model\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "qVm6OVeUCGSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executive Summary\n",
        "**Goal:** This project explores the relationship between daily physical activity and cardiovascular health, specifically Resting Heart Rate (RHR).\n",
        "**Method:** Using personal Apple Watch data and public Fitbit data, I analyzed the impact of Steps, Active Calories, and Sleep on RHR using Linear Regression and Random Forest models.\n",
        "**Key Findings:**\n",
        "1.  **Long-Term vs. Short-Term:** Consistent activity over months lowers RHR, but high-intensity days can temporarily raise RHR due to recovery demands.\n",
        "2.  **The Role of Sleep:** For the general population (Fitbit), sleep duration was the strongest predictor of improved heart health.\n",
        "3.  **Model Performance:** While daily physiological noise limits prediction accuracy ($R^2 \\approx 0.25$), the models successfully identified the key drivers of heart health."
      ],
      "metadata": {
        "id": "gjjPuggVRlrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project 1"
      ],
      "metadata": {
        "id": "QhmgiHrN1fhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem Definition\n",
        "---\n",
        "I aim to build a predictive model that estimates resting heart rate based on workout intensity and intensity measures. The purpose of the model is to determine weather increased physical activity leads to improvement in cardiovascular health, as reflected in resting heart rate. This model can help identify weather higher intensity or frequency of workouts is correlated with lower resting heart rate over time, which is often considered an indicator of improved fitness and heart health.\n",
        "\n",
        "It is intresting to me because I'm really into fitness and I have personally noticed how higher intensity workouts seem to affect my resting heart rate over the course of a week. By exploring this  through data, I would like to move beyond casual observations and see the relationship implemented in a measurable and quantifiable way, rather than just looking at raw numbers."
      ],
      "metadata": {
        "id": "MVYGYbg6C2Ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Describing the population\n",
        "---\n",
        "The population of interest is fitness enthusiasts who track daily workouts and health metrics using wearable devices such as apple watch, fitbit or similar tools. For this project I'll analyze a hybrid sample composed of\n",
        "```\n",
        "(1) My personal apple watch exports (daily heart rate, workouts, calories, sleep)\n",
        "(2) A public multiuser wearable dataset from kaggle.\n",
        "```\n",
        "The combined sample lets me present a personal case study while also evaluating wheather the personal patterns generalize across a larger group of wearable users with varied fitness levels and demographics."
      ],
      "metadata": {
        "id": "9XffwrZJL-wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Variables\n",
        "---\n",
        "####Independant variable (IV) - predictors related to workout intensity and volume\n",
        "    Workout duration(Minute per day)\n",
        "    Active calories burned (Kcal per day)\n",
        "    Average heart rate during workouts(bpm)\n",
        "    Number of workouts per week(count)\n",
        "    Steps per day(Optional activity proxy)\n",
        "    Sleep duration(hours per night) - treated as a predictor and as a confounder control.\n",
        "####Dependant Variable (DV) - The target variable to predict/measure\n",
        "    Resting heart rate(RHR), measured as daily(or weekly) average resting HR in beats per minute(bpm)\n",
        "####Confounding Variables\n",
        "    A confounder is an external factor that influences both the IVs and DVs and thus can create a biased association if not accounted for.\n",
        "Potential confounders in this project\n",
        "- Sleep quantity/duration (poor sleep raises RHR and may reduce workout intensity)\n",
        "- Stress or psychological load(Raises RHR and may affect workout patterns)\n",
        "- Illness or medication(temporarily raises RHR and alters activity)\n",
        "- Caffeine/alcohol intake or dehydration(affects HR measurements)\n",
        "- Age, Sex, and Baseline fitness levels( Since it is a multiuser data)\n",
        "- Measurement differences across devices(Apple watch vs Fitbit sensor characteristics)\n",
        "####Dealing with confounders\n",
        "- Measure and include where possible: include sleep duration from apple health/kaggle sleep fields as a covariate in alanyses.\n",
        "- Log/flag anomalies: create binary flags for days with illness, travel or medication if recorded and remove or mark extreme outliers in public dataset.\n",
        "- Control between-subject factors: While using the kaggle multiuser data, include user-level covariates(age,sex) and either run per-user analyses or by fitness level or use mixed effects models to account for baseline differences.\n",
        "- Device harmonisation: align units and aggregate to daily summaries and note device source as a covariate.\n",
        "- Smoothing: Apply rolling averages to resting HR tp reduce day-to-day noise and focus on underlying trends.\n",
        "- Sensitivity analyses: run models with and without certain covariates to show robustness of results and explicitly discuss remaining limitations."
      ],
      "metadata": {
        "id": "Ra7un3irIlnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hypothesis\n",
        "---\n",
        "- Changes in workout intensity and volume are not assiciated with changes in resting heart rate overtime (Null Hypothesis)\n",
        "- Increased workout intensity or volume(higher duration, higher active calories, higher average workout HR) is associated with a decrease in resting heart rate over time (Alternate hypothesis)\n",
        "\n",
        "###Lecture style hypothesis\n",
        "- If workout intensity increases measured by increased duration, increased active calories and higher average workout HR then resting heart rate will decrease over time."
      ],
      "metadata": {
        "id": "UC-hLpoLNU-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Collection\n",
        "---\n",
        "- Collected Data\n",
        "    1. Personal Apple watch data\n",
        "        - Exported from Apple health app: Health auto export to create CSVs\n",
        "        - Extract and standardise fields: Date, resting heart rate, workout start/end, duration, average workout HR, active calories, steps, sleep duration.\n",
        "    2. Public kaggle wearable dataset\n",
        "        - Download a kaggle fitbit-style dataset that includes heart rate, activity and sleep fields\n",
        "        - Inspect the schema and aggregate to a daily summary per user(resting HR, total active calories, total workout minutes, steps, sleep hours)\n",
        "- Ensure Representativeness when using the sample\n",
        "    1. The personal dataset represents a single-case study and is explicitly presented as such, valuable for authencity but not generalizable alone.\n",
        "    2. The kaggle dataset provides multi-user coverage to improve generalizability. I'll describe it's sample size, age/sex distribution(if available) and device types.\n",
        "    3. To avoid generalizing, I'll\n",
        "        - Run seperate analyses on the personal dataset and the public dataset, then comapre results.\n",
        "        - Use per-user aggregation and mixed-effects modeling on the public dataset to caputure within and between person effects.\n",
        "        - Transparently report limitations: the hybrid sample may still be baised toward wearable users, who are not a random sample of the general population.\n",
        "- Methods I'll use to collect data\n",
        "    1. Personal: direct extract from Apple health, converted to CSV. Logging any revelant notes(illness, travel, unsual sleep, caffine/alcohol) in a simple dairy CSV to merge with physiological records.\n",
        "    2. Public: Download official CSVs from kaggle, perform schema inspection. If minute level, aggregate to daily or per-workout summaries(average workout HR, calories, duration)"
      ],
      "metadata": {
        "id": "SaGJB8pyQE48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Choosing a Dataset\n",
        "---\n",
        "1. For this project, I'll be using a hybrid dataset\n",
        "    - My personal Apple watch health export: Which has daily resting heart rate, workout minutes, active calories, steps and sleep duration.\n",
        "    - Fitbit fitness tracker data from kaggle: Which contains multiple CSV files with daily activity, heart rate, calories and sleep information from multiple users.\n",
        "2. Why this datset is intrestign to me:\n",
        "    - I'm personally very passionate about fitness and have seen how my workout intensity affects my resting heart rate over time. By combining my own wearable health data with a larger, publicly avaible dataset of fitbit users, I can explore both my individual patterns and comapre them to a broader population. This makes the project authentic, personally meainingful and at the same time generalizable to a larger group. It also allows me to answer the research question in a way that goes beyond numbers and provides quantifiable insights into the relationships between exercise intensity and cardiovascular health.\n",
        "3. What is in the dataset?\n",
        "    - Apple Watch Data(Personal Export)\n",
        "        - Resting heart rate(daily average bpm)\n",
        "        - Workout duration(minutes)\n",
        "        - Active calories burned(kcal)\n",
        "        - Average heart rate during workouts(bpm)\n",
        "        - Steps per day\n",
        "        - Sleep duration\n",
        "    - Fitbit Dataset(MÃ¶bius / Kaggle):\n",
        "        - Daily activity: Total steps, calories burned, active minutes\n",
        "        - Heart rate: minute-level and daily avarage heart rate per user.\n",
        "        - Sleep data: total sleep time, sleep records, time in bed.\n",
        "        - Demographics: via user ID, with multiple participants tracked\n",
        "This Dataset has multiple variable and can be aggregated into daily records suitable for current projects's analysis.\n",
        "\n",
        "4. Where is the data set from?\n",
        "    - My Apple watch data was exported directly from the Apple Health App\n",
        "    - The fitbit dataset was obtained from kaggle: https://www.kaggle.com/datasets/arashnic/fitbit\n",
        "    \n",
        "The kaggle data is public facing and free to use the fitbit dataset is avaiable under Kaggle's public dataset license and my personal health export is my own data which i have full permission to use.\n",
        "\n",
        "5. When is the dataset from?\n",
        "    - My Apple Health dataset covers my recent daily healthg metrics(collected over several years)\n",
        "    - The Fitbit dataset was originally collected in 2016 as part of a personal fitness tracker study and made publicly available on kaggle for educational and analytical purposes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8_Sc82EbUYJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Data into Colab\n",
        "- CSV files from both the sources are copied into google drive.\n",
        "- Will import them from google drive to Colab and print the first 5 data entries from the file"
      ],
      "metadata": {
        "id": "wu-wVhA9jjUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the google drive below and then providing the path to apple health data which is currently in CSV format and then asking the pandas library to read the CSV and the storing it in a new variable. Lastly reading the first 5 records of the data."
      ],
      "metadata": {
        "id": "ib3dsXBiq3NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "fbZEsoGcCYR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AppleHealthData = '/content/drive/MyDrive/Datasets/AppleHealthExport.csv'\n",
        "\n",
        "\n",
        "AppleHealthData = '../data/AppleHealthExport.csv'\n",
        "\n",
        "if os.path.exists(AppleHealthData):\n",
        "    df_appleHealthData = pd.read_csv(AppleHealthData)\n",
        "    print(\"Apple Health Data Loaded Successfully\")\n",
        "else:\n",
        "    print(f\"Warning: {AppleHealthData} not found. Please ensure data is in the 'data' directory.\")\n",
        "\n",
        "\n",
        "df_appleHealthData.head()"
      ],
      "metadata": {
        "id": "Z2EFjE7elXlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the kaggle data into colab\n",
        "\n",
        "Providing the path for activity and sleep CSVs, then reading both the CSVs and printing the first 5 rows."
      ],
      "metadata": {
        "id": "5EwtWbRHqMi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "# activity_path = '/content/drive/MyDrive/Datasets/FitbitData/dailyActivity_merged.csv'\n",
        "# sleep_path = '/content/drive/MyDrive/Datasets/FitbitData/minuteSleep_merged.csv'\n",
        "# heart_rate = '/content/drive/MyDrive/Datasets/FitbitData/heartrate_seconds_merged.csv'\n",
        "\n",
        "activity_path = '../data/dailyActivity_merged.csv'\n",
        "sleep_path = '../data/minuteSleep_merged.csv'\n",
        "heart_path = '../data/heartrate_seconds_merged.csv'\n",
        "\n",
        "\n",
        "# Load the datasets into pandas DataFrames\n",
        "if os.path.exists(activity_path):\n",
        "    df_activity = pd.read_csv(activity_path)\n",
        "    print(\"Apple Health Data Loaded Successfully\")\n",
        "else:\n",
        "    print(f\"Warning: {activity_path} not found. Please ensure data is in the 'data' directory.\")\n",
        "\n",
        "\n",
        "if os.path.exists(sleep_path):\n",
        "    df_sleep = pd.read_csv(sleep_path)\n",
        "    print(\"Apple Health Data Loaded Successfully\")\n",
        "else:\n",
        "    print(f\"Warning: {sleep_path} not found. Please ensure data is in the 'data' directory.\")\n",
        "\n",
        "\n",
        "if os.path.exists(heart_rate):\n",
        "    df_heart_rate = pd.read_csv(heart_rate)\n",
        "    print(\"Apple Health Data Loaded Successfully\")\n",
        "else:\n",
        "    print(f\"Warning: {heart_rate} not found. Please ensure data is in the 'data' directory.\")\n"
      ],
      "metadata": {
        "id": "GBJX4-0QMDF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first few rows of Activity Dataset\n",
        "print(\"Activity Data:\")\n",
        "df_activity.head()"
      ],
      "metadata": {
        "id": "4s_tX5flr12p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first few rows of Sleep Dataset in minute format (will clean and pre process the data in project 2)\n",
        "print(\"\\nSleep Data:\")\n",
        "df_sleep.head()"
      ],
      "metadata": {
        "id": "BAeWmmvmqYtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nHeart Rate Data:\")\n",
        "df_heart_rate.head()"
      ],
      "metadata": {
        "id": "gfaL7Xwg2qa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project 2"
      ],
      "metadata": {
        "id": "K0BzaX-w1clN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Data Cleaning Strategy**\n",
        "\n",
        "> In this section, I'll prepare the data for analysis. The raw data from Apple Health and Fitbit contains formatting inconsistencies and missing values that must be addressed.\n",
        "\n",
        "**Key Actions**\n",
        "* **Merging:** I'll combine separate CSV files (steps, calories, heart rate) into a single master dataframe based on the 'Date' index.\n",
        "\n",
        "* **Filtering:** I will remove days with biologically impossible values (e.g., resting heart rate of 0) to prevent skewing the model.\n",
        "\n",
        "* **Formatting:** I will convert all date strings into datetime objects to allow for time-series analysis."
      ],
      "metadata": {
        "id": "TdtKNRlsRues"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Getting the **preliminary information** about the dataset\n",
        "\n",
        "#### i) Getting the shape using .shape fucntion for the below dataframes\n",
        "  - Personal data from Apple\n",
        "  - Fitbit activity data\n",
        "  - Fitbit sleep data\n",
        "  - Fitbit heart rate"
      ],
      "metadata": {
        "id": "tl8m0TJ10RLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of the datasets\n",
        "\n",
        "print('The shape of personal dataset is', df_appleHealthData.shape)\n",
        "print('The shape of public activity dataset is', df_activity.shape)\n",
        "print('The shape of public sleep dataset is', df_sleep.shape)\n",
        "print('The shape of public heart rate dataset is', df_heart_rate.shape)"
      ],
      "metadata": {
        "id": "Lra1FA83ryf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ii) Checking the data types of each cloumn using .dtypes fucntion for below dataframes\n",
        "  - Personal data from Apple\n",
        "  - Fitbit activity data\n",
        "  - Fitbit sleep data\n",
        "  - Fitbit heart rate"
      ],
      "metadata": {
        "id": "YRco1TuAHjBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DataTypes in the data\n",
        "print('The datatypes of personal dataset is\\n', df_appleHealthData.dtypes)\n",
        "print('\\nThe datatypes of public activity dataset is\\n', df_activity.dtypes)\n",
        "print('\\nThe datatypes of public sleep dataset is\\n', df_sleep.dtypes)\n",
        "print('\\nThe datatypes of public heart rate dataset is\\n', df_heart_rate.dtypes)"
      ],
      "metadata": {
        "id": "JY_mXfZb0jQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### iii) Listing all columns from both my personal and public dataframes using .columns function. Below are the dataframes,\n",
        "  - Personal data from Apple\n",
        "  - Fitbit activity data\n",
        "  - Fitbit sleep data\n",
        "  - Fitbit heart rate"
      ],
      "metadata": {
        "id": "GHuIRa_fI_on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns/variables in the data\n",
        "print('The columns of personal dataset is\\n', df_appleHealthData.columns)\n",
        "print('\\nThe columns of public activity dataset is\\n', df_activity.columns)\n",
        "print('\\nThe columns of public sleep dataset is\\n', df_sleep.columns)\n",
        "print('\\nThe columns of public heart rate dataset is\\n', df_heart_rate.columns)"
      ],
      "metadata": {
        "id": "ZwSuRkE-28AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####iv) Listing the number of unique elements from each column using .nunique function.\n",
        "  - Personal data from Apple\n",
        "  - Fitbit activity data\n",
        "  - Fitbit sleep data\n",
        "  - Fitbit heart rate"
      ],
      "metadata": {
        "id": "8BlV7IFxJ4Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unique elements in the data\n",
        "print('\\nThe unique elements of personal dataset is\\n', df_appleHealthData.nunique())\n",
        "print('\\nThe unique elemsnts in public activity dataset is\\n', df_activity.nunique())\n",
        "print('\\nThe unique elemsnts in public sleep dataset is\\n', df_sleep.nunique())\n",
        "print('\\nThe unique elemsnts in public heart rate dataset is\\n', df_heart_rate.nunique())"
      ],
      "metadata": {
        "id": "N-R4neYM3boR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####v) Describing the dataframes using .describe function for the following dataframes\n",
        "  - Personal data from Apple\n",
        "  - Fitbit activity data\n",
        "  - Fitbit sleep data\n",
        "  - Fitbit heart rate  "
      ],
      "metadata": {
        "id": "cE583lJMK18O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#describing the datasets\n",
        "print('\\nThe description of personal dataset is\\n', df_appleHealthData.describe())\n",
        "print('\\nThe description of public activity dataset is\\n', df_activity.describe())\n",
        "print('\\nThe description of public sleep dataset is\\n', df_sleep.describe())\n",
        "print('\\nThe description of public heart rate dataset\\n', df_heart_rate.describe())"
      ],
      "metadata": {
        "id": "cjUpQM3n38Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Specific data needs for this project\n",
        "  - I have multiple data sets that needs to be merged\n",
        "  - One is a personal dataset from my fitness app and the other is a public dataset from kaggle.\n",
        "  - I have a export of my personal dataset and the dataframe is called df_appleHealthData and multiple csv files from kaggle datasets from which i'm taking in just the activity, sleep and heart rate data which are named as df_activity, df_sleep and df_heart_rate respectively.\n"
      ],
      "metadata": {
        "id": "J0wWOwEiLNq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing the data and standardising it\n",
        "\n",
        "####1. Standardizing Date/Time Columns across the board using pandas's to_datetime funtion."
      ],
      "metadata": {
        "id": "sPk4pNELObJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_appleHealthData['date'] = pd.to_datetime(df_appleHealthData['date']).dt.date\n",
        "df_activity['ActivityDate'] = pd.to_datetime(df_activity['ActivityDate']).dt.date\n",
        "df_sleep['date'] = pd.to_datetime(df_sleep['date']).dt.date\n",
        "df_heart_rate['Time'] = pd.to_datetime(df_heart_rate['Time']).dt.date"
      ],
      "metadata": {
        "id": "MUG30nNk_M_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_activity.head()"
      ],
      "metadata": {
        "id": "-G2_nOE7B5LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_appleHealthData.head()"
      ],
      "metadata": {
        "id": "UiEnebu0CMaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_heart_rate.head()"
      ],
      "metadata": {
        "id": "PUIUK4K8CpQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sleep.head()"
      ],
      "metadata": {
        "id": "mlc5K4jCCRCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Aggregate Sleep and Heart Rate Data\n",
        "Aggregate sleep data to get total minutes asleep per day for each user\n"
      ],
      "metadata": {
        "id": "DAgcj4oYQyb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'value' of 1 in the sleep data represents one minute of sleep\n",
        "df_sleep_daily = df_sleep.groupby(['Id', 'date']).agg(\n",
        "    TotalMinutesAsleep=('value', 'sum')\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "zcZATKwDBNU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregate heart rate data to get a proxy for resting heart rate (RHR)\n",
        "\n",
        "I choose to take the minimum heart rate value recorded for that day."
      ],
      "metadata": {
        "id": "bG1LHChjRQQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_rhr_daily = df_heart_rate.groupby(['Id', 'Time']).agg(\n",
        "    RestingHeartRate=('Value', 'min')\n",
        ").reset_index()"
      ],
      "metadata": {
        "id": "3lL8gyKYRR7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Merge the Fitbit Datasets\n",
        "\n",
        "Merge activity with daily sleep"
      ],
      "metadata": {
        "id": "KeK2PTw_RlWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a left merge to keep all activity records\n",
        "df_fitbit_merged = pd.merge(df_activity, df_sleep_daily,\n",
        "                            left_on=['Id', 'ActivityDate'],\n",
        "                            right_on=['Id', 'date'],\n",
        "                            how='left')\n",
        "\n",
        "# Merging the result with daily resting heart rate\n",
        "df_fitbit_merged = pd.merge(df_fitbit_merged, df_rhr_daily,\n",
        "                            left_on=['Id', 'ActivityDate'],\n",
        "                            right_on=['Id', 'Time'],\n",
        "                            how='left')\n",
        "\n",
        "# Drop redundant date columns from the merges\n",
        "df_fitbit_merged = df_fitbit_merged.drop(columns=['date', 'Time'])\n",
        "\n",
        "print(\"Merged Fitbit data. Here is the preview:\")\n",
        "df_fitbit_merged.head()"
      ],
      "metadata": {
        "id": "0WFfa9P8BsAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_heart_rate.head()"
      ],
      "metadata": {
        "id": "C15kQWaNBx8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rhr_daily.head()"
      ],
      "metadata": {
        "id": "NoVqOUcUEJhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitbit_merged.head()"
      ],
      "metadata": {
        "id": "KwtuKHPaEQGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitbit_merged['RestingHeartRate'].value_counts()"
      ],
      "metadata": {
        "id": "2L_nUDESEY9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitbit_merged['ActivityDate'].value_counts()"
      ],
      "metadata": {
        "id": "vdpfq-E0En5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_heart_rate.info()"
      ],
      "metadata": {
        "id": "WE925EdkFtB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_heart_rate['Id'].value_counts()"
      ],
      "metadata": {
        "id": "lyB93idIFC2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitbit_merged['Id'].value_counts()"
      ],
      "metadata": {
        "id": "du-kCLymFgh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing seaborn and matplotlib to help visualize the data"
      ],
      "metadata": {
        "id": "fZWNnqxGUGIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-0RVRVEMUDCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Potential issues in the data.\n",
        "#### Investigating the personal data and checking for any potential issues  "
      ],
      "metadata": {
        "id": "oyT0wCQoVJrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Investigating Apple Health Data\")\n",
        "# Checking for missing or null values\n",
        "print('=' * 60)\n",
        "print(\"\\nMissing Values (Apple): \")\n",
        "print(df_appleHealthData.isnull().sum())\n",
        "\n",
        "# Checking for Duplicates in the personal dataframe\n",
        "print('=' * 60)\n",
        "print(f\"\\nNumber of duplicate rows (Apple): {df_appleHealthData.duplicated().sum()}\")\n",
        "\n",
        "# Checking for outliers\n",
        "print(\"\\nChecking for Outliers (Apple)...\")\n",
        "# The 'resting' column has a '0' value which is impossible.\n",
        "print(\"Description of 'resting' column shows a min of 0, which is an outlier:\")\n",
        "print(df_appleHealthData['resting'].describe())\n"
      ],
      "metadata": {
        "id": "KgTqnmR2UC9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the outliers with a boxplot\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.boxplot(x=df_appleHealthData['resting'])\n",
        "plt.title('Boxplot of Resting Heart Rate (Apple Data)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BfAvqz9BUC3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see couple of outliers but there is one potential issue with 0 resting heart rate which is not possible. I will remove the value from dataframe while cleaning the data."
      ],
      "metadata": {
        "id": "OyypdC0aYd7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Investigating the public dataset from kaggle, where i have merged all the required data and created a single dataframe called df_fitbit_merged and checking for any potential issues."
      ],
      "metadata": {
        "id": "7AC3As_sVsFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigating Merged Fitbit Data\n",
        "print(\"\\n--- Investigating Merged Fitbit Data ---\")\n",
        "# Checking for missing or null values\n",
        "print(\"\\nMissing Values (Fitbit):\")\n",
        "print(df_fitbit_merged.isnull().sum())\n",
        "\n",
        "# Checking duplicates\n",
        "print(f\"\\nNumber of duplicate rows (Fitbit): {df_fitbit_merged.duplicated().sum()}\")\n",
        "\n",
        "# Checking for outliers\n",
        "print(\"\\nChecking for Outliers (Fitbit)...\")\n",
        "# Checking for days with 0 calories burned but with steps recorded, which is illogical data.\n",
        "illogical_data = df_fitbit_merged[(df_fitbit_merged['Calories'] == 0) & (df_fitbit_merged['TotalSteps'] > 0)]\n",
        "print(f\"Found {len(illogical_data)} rows with 0 calories but > 0 steps.\")"
      ],
      "metadata": {
        "id": "wV4mV5a-F8H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The left joins likely introduced NaNs where sleep or heart rate data was missing for a given activity day."
      ],
      "metadata": {
        "id": "myivJPWuW4X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Reorganisation\n",
        "My workflow will be to clean the data first, addressing issues like unwanted columns. Then, I'll perform reorganization tasks like renaming the remaining necessary columns for better clarity and consistency. This seems more efficient than renaming potentially temporary columns."
      ],
      "metadata": {
        "id": "jY6K3_esZGmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Developing a detailed plan for cleaning the data\n",
        "  - Apple Health Dataset(df_appleHealthData)\n",
        "    - Issue 1: Several Coulmns(systolic, diastolic, bpreadtime, glucose, glucose_read_time, glucose_meal) are entirely null.\n",
        "      - Action: These columns will be dropped\n",
        "      - Technique: will use df.drop(columns=[...])\n",
        "      - Why: Contains no information and are irrelevant to the analysis.\n",
        "    - Issue 2: The blood oxygen column is not needed and has 1 null value.\n",
        "      - Action: This column will be dropped\n",
        "      - Technique: df.drop(columns=[...])\n",
        "      - Why: It is not part of core variables(Unneeded variable for our current analysis)\n",
        "    - Issue 3: Columns like minimum, maximum, average, activity, variability, and weight provide detailed heart rate stats or other metrics not central to the primary hypothesis\n",
        "      - Action: These columns will be dropped to simplify the dataset.\n",
        "      - Technique: df.drop(columns=[...]).\n",
        "      - Why: To focus on the key predictors (steps, calories, sleep) and the target (resting heart rate).\n",
        "    - Issue 4: The date column is of object type\n",
        "      - Action: Convert to datetime objects\n",
        "      - Technique: pd.to_datetime(df['date']).\n",
        "      - Why: Essential for time-series analysis and proper data handling.\n",
        "    - Issue 5: The resting heart rate column contains outlier values of 0.\n",
        "      - Action: Remove rows where resting is 0 (or less than a realistic minimum, e.g., 30 bpm).\n",
        "      - Technique: Boolean indexing: df_apple_cleaned = df_apple_cleaned[df_apple_cleaned['resting'] > 0].\n",
        "      - Why: These values are physiologically impossible and represent data errors.\n",
        "    - Reorganization (Post-Cleaning):\n",
        "      - Action: Rename columns for clarity and consistency with the Fitbit data.\n",
        "      - Technique: df.rename(columns={'date': 'Date', 'resting': 'RestingHeartRate', 'calories': 'ActiveCalories', 'sleep': 'TotalMinutesAsleep', 'steps': 'TotalSteps'})- Why: Improves readability and prepares for potential comparison or merging."
      ],
      "metadata": {
        "id": "BlVjKY_laAGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Merged Fitbit Dataset (df_fitbit_merged)\n",
        "\n",
        "    - Issue 1: TotalMinutesAsleep and RestingHeartRate columns contain missing values (NaN), likely due to the merging process and users lacking data for certain days.\n",
        "      - Action: Fill these missing values\n",
        "      - Technique: Use a two-step imputation:\n",
        "        - Fill NaNs using the median value for that specific user (Id). Use df.groupby('Id')[column].transform(lambda x: x.fillna(x.median())).\n",
        "        - Fill any remaining NaNs (for users with no data at all) using the overall median of the entire column. Use df[column].fillna(df[column].median(), inplace=True).\n",
        "      - Why: This preserves user-specific patterns where available while ensuring no data rows are lost solely due to missing sleep/RHR. The median is robust to outliers.\n",
        "\n",
        "    - Issue 2: Some rows might have 0 Calories despite having TotalSteps > 0.\n",
        "      - Action: Remove rows where Calories is 0.\n",
        "      - Technique: Boolean indexing: df_fitbit_cleaned = df_fitbit_cleaned[df_fitbit_cleaned['Calories'] > 0].\n",
        "      - Why: These represent impossible scenarios, likely data logging errors.\n",
        "\n",
        "    - Issue 3: The dataset contains many activity-related columns (TotalDistance, TrackerDistance, various active distance/minute columns) that are redundant or not needed for the core analysis.\n",
        "      - Action: Keeping only the essential columns to match the simplified Apple data: Id, Date, TotalSteps, Calories, TotalMinutesAsleep, RestingHeartRate.\n",
        "      - Technique: df_fitbit_cleaned = df_fitbit_cleaned[['Id', 'Date', ...]].\n",
        "      - Why: Creates a focused, consistent dataset structure across both sources.\n",
        "\n",
        "    - Reorganization (Post-Cleaning):\n",
        "      - Action: Rename columns for consistency.\n",
        "      - Technique: df.rename(columns={'ActivityDate': 'Date', 'Calories': 'ActiveCalories'}).\n",
        "      - Why: Ensures column names match the Apple dataset exactly."
      ],
      "metadata": {
        "id": "bbBOI4skdRFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Cleaning the data"
      ],
      "metadata": {
        "id": "fsdBJGDvfQnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cleaning the personal dataset as per the created plan"
      ],
      "metadata": {
        "id": "HtYZWTcckgbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning my personal health dataset\n",
        "print(\"Cleaning Apple Health Data...\")\n",
        "df_apple_cleaned = df_appleHealthData.copy()\n",
        "#Solving issue 1, issue 2, issue 3\n",
        "cols_to_drop_apple = [\n",
        "    'systolic', 'diastolic', 'bpreadtime', 'glucose', 'glucose_read_time',\n",
        "    'glucose_meal', 'bloodoxygen', 'minimum', 'maximum', 'average',\n",
        "    'activity', 'variability', 'weight'\n",
        "]\n",
        "df_apple_cleaned = df_apple_cleaned.drop(columns=cols_to_drop_apple)\n",
        "#Solving issue 4\n",
        "df_apple_cleaned['date'] = pd.to_datetime(df_apple_cleaned['date'])\n",
        "#solving issue 5\n",
        "df_apple_cleaned = df_apple_cleaned[df_apple_cleaned['resting'] > 0]\n",
        "df_apple_cleaned.rename(columns={\n",
        "    'date': 'Date', 'resting': 'RestingHeartRate', 'calories': 'ActiveCalories',\n",
        "    'sleep': 'TotalMinutesAsleep', 'steps': 'TotalSteps'\n",
        "}, inplace=True)\n",
        "\n",
        "print(f\"Apple data cleaned.\\nNew shape is now: {df_apple_cleaned.shape}\")\n"
      ],
      "metadata": {
        "id": "lHTsUbjSIXGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Cleaning the fitbit dataset as per the plan"
      ],
      "metadata": {
        "id": "Xkg1A0pJkrck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the Merged Fitbit Dataset\n",
        "print(\"\\nCleaning Merged Fitbit Data...\")\n",
        "df_fitbit_cleaned = df_fitbit_merged.copy()\n",
        "\n",
        "#Solving issue 2\n",
        "df_fitbit_cleaned = df_fitbit_cleaned[df_fitbit_cleaned['Calories'] > 0].copy()\n",
        "\n",
        "# solving issue 1, Robustly fill missing values\n",
        "df_fitbit_cleaned['TotalMinutesAsleep'] = df_fitbit_cleaned.groupby('Id')['TotalMinutesAsleep'].transform(lambda x: x.fillna(x.median()))\n",
        "df_fitbit_cleaned['RestingHeartRate'] = df_fitbit_cleaned.groupby('Id')['RestingHeartRate'].transform(lambda x: x.fillna(x.median()))\n",
        "df_fitbit_cleaned['TotalMinutesAsleep'] = df_fitbit_cleaned['TotalMinutesAsleep'].fillna(\n",
        "    df_fitbit_cleaned['TotalMinutesAsleep'].median()\n",
        ")\n",
        "\n",
        "df_fitbit_cleaned['RestingHeartRate'] = df_fitbit_cleaned['RestingHeartRate'].fillna(\n",
        "    df_fitbit_cleaned['RestingHeartRate'].median()\n",
        ")\n",
        "\n",
        "#Renaming the columns to match with personal data\n",
        "df_fitbit_cleaned = df_fitbit_cleaned.rename(columns={'ActivityDate': 'Date'})\n",
        "\n",
        "# Selecting and reordeing columns to match the personal dataset\n",
        "essential_cols = [\n",
        "    'Id',\n",
        "    'Date',\n",
        "    'TotalSteps',\n",
        "    'Calories',\n",
        "    'TotalMinutesAsleep',\n",
        "    'RestingHeartRate'\n",
        "]\n",
        "df_fitbit_cleaned = df_fitbit_cleaned[essential_cols]\n",
        "\n",
        "print(f\"Fitbit data cleaned and simplified. Shape is now: {df_fitbit_cleaned.shape}\")\n",
        "\n",
        "# Verifing if all the things have been handeled.\n",
        "print(\"\\nMissing values after FINAL cleaning of Fitbit data:\")\n",
        "print(df_fitbit_cleaned.isnull().sum())"
      ],
      "metadata": {
        "id": "mXBJFze6gxMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. Saving the clean data"
      ],
      "metadata": {
        "id": "lTTnKFJdk7Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining file paths for the cleaned data\n",
        "apple_cleaned_path = '../data/AppleHealthData_cleaned.csv'\n",
        "fitbit_cleaned_path = '../data/FitbitData_cleaned.csv'\n",
        "\n",
        "# Saving the dataframes to CSV\n",
        "df_apple_cleaned.to_csv(apple_cleaned_path, index=False)\n",
        "df_fitbit_cleaned.to_csv(fitbit_cleaned_path, index=False)\n",
        "\n",
        "print(f\"Cleaned Apple data saved to: {apple_cleaned_path}\")\n",
        "print(f\"Cleaned Fitbit data saved to: {fitbit_cleaned_path}\")"
      ],
      "metadata": {
        "id": "KF5_YSqgIgnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. Importing the cleaned files"
      ],
      "metadata": {
        "id": "8i7l22m9lIFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the cleaned files\n",
        "df_apple_final = pd.read_csv(apple_cleaned_path)\n",
        "df_fitbit_final = pd.read_csv(fitbit_cleaned_path)\n",
        "\n",
        "print(\"Successfully re-imported the cleaned data files.\")"
      ],
      "metadata": {
        "id": "_HFQQfDEIi11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10. Printing the first and last 5 rows of both datasets"
      ],
      "metadata": {
        "id": "UgPWBRY_n820"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing personal data\n",
        "print(\"=\" * 60)\n",
        "print(\"Final Cleaned Apple Data\")\n",
        "print(\"First 5 entries:\")\n",
        "print(df_apple_final.head())\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nLast 5 entries:\")\n",
        "print(df_apple_final.tail())\n",
        "\n",
        "\n",
        "#Printing Fitbit data\n",
        "print(\"=\" * 60)\n",
        "print(\"--- Final Cleaned Fitbit Data ---\")\n",
        "print(\"First 5 entries:\")\n",
        "print(df_fitbit_final.head())\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nLast 5 entries:\")\n",
        "print(df_fitbit_final.tail())"
      ],
      "metadata": {
        "id": "5HWJZKCrIlhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_apple_final.info()"
      ],
      "metadata": {
        "id": "soZVNIXXnbCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fitbit_final.info()"
      ],
      "metadata": {
        "id": "k33UE_vVndxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "bW7FGl3j70yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Project 3 : Data Exploration and Visual"
      ],
      "metadata": {
        "id": "iw-0gTC2a5P7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Capture Initial Thoughts\n",
        "\n",
        "> - Do you think you have the right data? Yes, I believe I have the right data. My goal is to see if workout intensity (my independent variable) affects resting heart rate (RHR), my dependent variable. Both my personal Apple Health data and the public Fitbit data contain a daily timestamp, measures of intensity (Active Calories, Total Steps), and the target variable (Resting Heart Rate).\n",
        "\n",
        "> - What are your initial questions?\n",
        "  >   1.   Is there a clear negative correlation between daily ActiveCalories and RestingHeartRate?\n",
        "  >   2.   Is this correlation stronger in my personal data compared to the aggregated public data?\n",
        "  >   3. Does TotalMinutesAsleep (my main confounder) have a strong correlation with RestingHeartRate?\n",
        "  >   4. Can I see a long-term trend of my RHR decreasing over time in my personal data?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L2KVwjPCbCnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3. Explore Characteristics of the Data\n",
        "\n",
        "Most of this preliminary check was completed in Project 2, but I'll re-verify the final cleaned files.\n",
        "\n",
        "> What does each record/row in the dataset represent?\n",
        "> - For df_apple_final: Each row represents a single day of my personal health data, including resting heart rate, steps, active calories, and sleep.\n",
        "> - For df_fitbit_final: Each row represents a single day of health data for one of the 35 unique users in the public dataset.\n",
        "\n",
        "> What variables/columns do you have?\n",
        "> - The code below will use .info() to list all columns, their data types, and their non-null counts. This confirms the columns I selected in Project 2.\n",
        "\n",
        "> Are there any duplicates? How do you know?\n",
        "> - I will use the .duplicated().sum() method on each DataFrame. This command checks every row against all other rows and provides a count of any exact duplicates.\n",
        "\n",
        "> Handling Duplicates:\n",
        "> - This step was performed during the pre-processing phase in Project 2. The code below will just confirm that the final, cleaned dataframes have zero duplicate rows. No further handling should be necessary."
      ],
      "metadata": {
        "id": "OVgqb1853r9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Apple Data: Characteristics ---\")\n",
        "print(\"\\nShape (Rows, Columns):\")\n",
        "print(df_apple_final.shape)\n",
        "\n",
        "print(\"\\nColumns and Data Types:\")\n",
        "df_apple_final.info()\n",
        "\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "print(f\"Found {df_apple_final.duplicated().sum()} duplicate rows.\")\n",
        "\n",
        "\n",
        "print(\"\\n\\n--- Fitbit Data: Characteristics ---\")\n",
        "print(\"\\nShape (Rows, Columns):\")\n",
        "print(df_fitbit_final.shape)\n",
        "\n",
        "print(\"\\nColumns and Data Types:\")\n",
        "df_fitbit_final.info()\n",
        "\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "print(f\"Found {df_fitbit_final.duplicated().sum()} duplicate rows.\")"
      ],
      "metadata": {
        "id": "2E8g3SNT4GEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Characteristics\n",
        "After running the code, I can confirm:\n",
        "\n",
        "> Shape:\n",
        "> - My personal Apple dataset (df_apple_final) has 728 rows and 5 columns.\n",
        "> - The public Fitbit dataset (df_fitbit_final) has 452 rows and 6 columns (the extra column is the Id for each user).\n",
        "\n",
        ">Variables:\n",
        "> - The df_apple_final.info() output confirms the 5 columns are: Date, RestingHeartRate, TotalSteps, ActiveCalories, and TotalMinutesAsleep. All are numeric except for Date, which is an object (I'll re-verify it's a datetime object in Step 5).\n",
        "> - The df_fitbit_final.info() output confirms the 6 columns are: Id, Date, TotalSteps, Calories, TotalMinutesAsleep, and RestingHeartRate.\n",
        "\n",
        "> Duplicates:\n",
        "> - The output confirms that there are 0 duplicate rows in both df_apple_final and df_fitbit_final, so no further action is needed."
      ],
      "metadata": {
        "id": "1mgXC4Ii-Q3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4. Additional Transformations/Manipulations\n",
        "\n",
        ">During Project 2, I already:\n",
        ">1. Converted all date columns to datetime objects.\n",
        ">2. Filled missing RHR and Sleep values in the Fitbit data using a user-by-user median, followed by a global median.\n",
        ">3. Removed the impossible 0 RHR entry from my Apple data.\n",
        "\n",
        "One key difference I noted is that df_apple_final has ActiveCalories, while df_fitbit_final has Calories (which is likely total calories, including BMR). This is not an apples-to-apples comparison.\n",
        "\n",
        "For this exploration, I will proceed using Calories as a proxy for the Fitbit users' activity, but I will rely more on TotalSteps (which is present in both) for a more direct comparison."
      ],
      "metadata": {
        "id": "bv73L8xC4DJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5. Explore Every Variable in the Dataset"
      ],
      "metadata": {
        "id": "bJuuQHhR4mOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descriptive Statistics\n",
        "\n",
        ">Here are the summary statistics for all numeric variables in both final dataframes, as required"
      ],
      "metadata": {
        "id": "QDfgxJdw8sIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive Statistics for Apple Data\n",
        "print(\"--- Apple Data: Descriptive Statistics ---\")\n",
        "print(df_apple_final.describe())\n",
        "\n",
        "# Descriptive Statistics for Fitbit Data\n",
        "print(\"\\n--- Fitbit Data: Descriptive Statistics ---\")\n",
        "print(df_fitbit_final.describe())"
      ],
      "metadata": {
        "id": "FgSFF02I8wM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Here, I'll analyze the distributions of my key independent variables (intensity measures) and the dependent variable (RHR)."
      ],
      "metadata": {
        "id": "wuie2utT8zqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Visualize personal Data Distributions\n",
        "print(\"Distributions for Personal Health Data\")\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Distributions of Key Metrics (Personal Data)')\n",
        "\n",
        "# Resting Heart Rate\n",
        "sns.histplot(df_apple_final['RestingHeartRate'], kde=True, ax=axes[0], color='blue')\n",
        "axes[0].set_title('Resting Heart Rate')\n",
        "\n",
        "# Active Calories\n",
        "sns.histplot(df_apple_final['ActiveCalories'], kde=True, ax=axes[1], color='red')\n",
        "axes[1].set_title('Active Calories Burned')\n",
        "\n",
        "# Total Steps\n",
        "sns.histplot(df_apple_final['TotalSteps'], kde=True, ax=axes[2], color='green')\n",
        "axes[2].set_title('Total Steps per Day')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualize Fitbit Data Distributions\n",
        "print(\"\\nDistributions for Public Fitbit Data\")\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Distributions of Key Metrics (Fitbit Data)')\n",
        "\n",
        "# Resting Heart Rate\n",
        "sns.histplot(df_fitbit_final['RestingHeartRate'], kde=True, ax=axes[0], color='blue')\n",
        "axes[0].set_title('Resting Heart Rate')\n",
        "\n",
        "# Active Calories (using 'Calories' column)\n",
        "sns.histplot(df_fitbit_final['Calories'], kde=True, ax=axes[1], color='red')\n",
        "axes[1].set_title('Total Calories Burned')\n",
        "\n",
        "# Total Steps\n",
        "sns.histplot(df_fitbit_final['TotalSteps'], kde=True, ax=axes[2], color='green')\n",
        "axes[2].set_title('Total Steps per Day')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T34uHkRk4eR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Visual Analysis (Histograms):\n",
        "\n",
        "- Resting Heart Rate (Apple): My personal RHR distribution is roughly normal, centered around 60 bpm. This looks very reasonable and clean.\n",
        "\n",
        "- Active Calories (Apple): This distribution is right-skewed. Most days have 500-1500 active calories, with a long tail representing days with very intense or long workouts.\n",
        "\n",
        "- Total Steps (Apple): Also right-skewed, with a primary peak around 10,000-12,000 steps.\n",
        "\n",
        "- Resting Heart Rate (Fitbit): This distribution is multi-modal, with several distinct peaks (e.g., ~53, ~60, ~68 bpm). This is expected, as it represents an aggregation of 35 different individuals, each with their own baseline RHR.\n",
        "\n",
        "- Total Calories (Fitbit): This distribution is much more \"normal\" (less skewed) than my 'Active Calories' plot. This supports the idea that it includes Basal Metabolic Rate (BMR), which makes the daily total more consistent.\n",
        "\n",
        "- Total Steps (Fitbit): This is also right-skewed, but the main peak is lower than my personal data, centered around 6,000-8,000 steps."
      ],
      "metadata": {
        "id": "7LC8Ay8E4-D8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5b. Initial Thoughts vs. Analysis\n",
        "\n",
        "> My findings from exploring the variables (Step 5) generally confirmed my initial questions (Step 2).\n",
        "> - I questioned if a negative correlation existed, and my analysis of the variables in the scatter plots and heatmaps confirmed that it does (e.g., -0.22 for ActiveCalories vs. RestingHeartRate in my data).\n",
        "> - I also questioned the role of sleep, and the correlation matrix confirmed TotalMinutesAsleep has a notable negative correlation with RHR in both datasets."
      ],
      "metadata": {
        "id": "Z1KOJF4T84gX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Below is a variable-by-variable analysis of the columns central to my hypothesis."
      ],
      "metadata": {
        "id": "Y25LrZMvDv5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure Date columns are in datetime format for plotting\n",
        "df_apple_final['Date'] = pd.to_datetime(df_apple_final['Date'])\n",
        "df_fitbit_final['Date'] = pd.to_datetime(df_fitbit_final['Date'])\n",
        "\n",
        "# --- Step 5: Explore Every Variable ---\n",
        "\n",
        "print(\"\\n--- [Step 5] Descriptive Statistics ---\")\n",
        "print(\"\\nApple Data Statistics:\")\n",
        "print(df_apple_final.describe())\n",
        "print(\"\\nFitbit Data Statistics:\")\n",
        "print(df_fitbit_final.describe())\n",
        "\n",
        "# --- Distributions (Histograms) ---\n",
        "print(\"\\n--- [Step 5] Plotting Variable Distributions ---\")\n",
        "\n",
        "# Set style for all plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot 1: Resting Heart Rate Distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "sns.histplot(df_apple_final['RestingHeartRate'], kde=True, ax=axes[0], color='blue')\n",
        "axes[0].set_title('Apple: RHR Distribution')\n",
        "sns.histplot(df_fitbit_final['RestingHeartRate'], kde=True, ax=axes[1], color='cyan')\n",
        "axes[1].set_title('Fitbit: RHR Distribution (Aggregated)')\n",
        "plt.savefig('P3_RHR_distributions.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Calories Distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "sns.histplot(df_apple_final['ActiveCalories'], kde=True, ax=axes[0], color='red')\n",
        "axes[0].set_title('Apple: Active Calories Distribution')\n",
        "sns.histplot(df_fitbit_final['Calories'], kde=True, ax=axes[1], color='orange')\n",
        "axes[1].set_title('Fitbit: Total Calories Distribution')\n",
        "plt.savefig('P3_Calories_distributions.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Total Steps Distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "sns.histplot(df_apple_final['TotalSteps'], kde=True, ax=axes[0], color='green')\n",
        "axes[0].set_title('Apple: Total Steps Distribution')\n",
        "sns.histplot(df_fitbit_final['TotalSteps'], kde=True, ax=axes[1], color='lime')\n",
        "axes[1].set_title('Fitbit: Total Steps Distribution')\n",
        "plt.savefig('P3_TotalSteps_distributions.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot 4: Total Minutes Asleep Distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "sns.histplot(df_apple_final['TotalMinutesAsleep'], kde=True, ax=axes[0], color='purple')\n",
        "axes[0].set_title('Apple: TotalMinutesAsleep Distribution')\n",
        "sns.histplot(df_fitbit_final['TotalMinutesAsleep'], kde=True, ax=axes[1], color='magenta')\n",
        "axes[1].set_title('Fitbit: TotalMinutesAsleep Distribution')\n",
        "plt.savefig('P3_TotalMinutesAsleep_distributions.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pLOpdEolDU6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Variable 1: RestingHeartRate (Dependent Variable)\n",
        "> - Datatype: int64 (Apple) and float64 (Fitbit), as seen in the .info() output.\n",
        "> - Units: Beats per minute (bpm). I know this as it is the standard medical unit for measuring heart rate.\n",
        "> - Represents: The target variable. It measures cardiovascular health and fitness. My hypothesis is that this value will decrease as intensity increases.\n",
        "> - Transformations: None needed. The variable is numeric and ready for modeling.\n",
        "> - Different from initial thoughts?: No, this is exactly what I expected.\n",
        "> - Missing Data or Outliers:\n",
        ">   - Apple: In Project 2, I identified and removed one extreme outlier (0 bpm), which is physiologically impossible.\n",
        ">   - Fitbit: In Project 2, I identified missing (NaN) values, which were the result of the merge operation.\n",
        "\n",
        "> Handling:\n",
        "> - The 0 bpm value in the Apple data was removed.\n",
        "> - The NaN values in the Fitbit data were imputed using the median RHR for that specific user, which is a robust way to handle missing data without skewing the results for that individual.\n",
        "\n",
        "> Descriptive Statistics:\n",
        "> - Apple: The mean is 60.96 bpm, with a standard deviation of 7.3. The values range from a min of 41 to a max of 88 (after cleaning), which is a very reasonable and healthy range.\n",
        "> - Fitbit: The mean is 54.9 bpm with a std of 6.5. This mean is lower than my personal average.\n",
        "\n",
        "> Distribution & Visuals:\n",
        "> - The RHR_distributions.png plot shows the two distributions.\n",
        "> - Apple (blue): The distribution is very clean and roughly normal, centered just over 60 bpm.\n",
        "> - Fitbit (cyan): The distribution is multi-modal (it has multiple peaks). This is expected, as it is a combination of 35 different people. Each peak (e.g., around 53, 60, 68 bpm) likely represents the average RHR for a different cluster of users.\n",
        "\n",
        "Variable 2: ActiveCalories (Apple) / Calories (Fitbit) (Independent Variable)\n",
        "\n",
        "> -  Datatype: int64 for both.\n",
        "> - Units: Kilocalories (kcal). This is the standard unit for energy expenditure.\n",
        "> - Represents: This is my primary proxy for workout intensity.\n",
        "> - Transformations: None needed for exploration.\n",
        "> - Different from initial thoughts?: Yes. My Apple data is Active Calories (energy burned from exercise), while the Fitbit data is Total Calories (Active + BMR). This makes a direct comparison difficult, as the Fitbit data is \"inflated\" by baseline metabolic calories.\n",
        "> - Missing Data or Outliers: In Project 2, I removed 5 rows from the Fitbit data where Calories was 0, which was illogical. The Apple data had no missing values.\n",
        "\n",
        "> Descriptive Statistics:\n",
        "> - Apple: The mean is 1004 kcal (Active), with a max of 3574 kcal.\n",
        "> - Fitbit: The mean is 2189 kcal (Total), with a max of 4562 kcal.\n",
        "\n",
        "> Distribution & Visuals:\n",
        "> - The Calories_distributions.png plot shows the two distributions.\n",
        "> - Apple (red): The distribution is highly right-skewed. This makes sense; most days have a moderate workout, and a few days have very long/intense workouts (e.g., a long run or hike), creating a long tail.\n",
        "> - Fitbit (orange): The distribution is much more normal and less skewed. This confirms that it includes BMR, which is fairly constant day-to-day and \"centers\" the data.\n",
        "\n",
        "Variable 3: TotalSteps (Independent Variable)\n",
        "> - Datatype: int64 for both.\n",
        "> - Units: Steps (count).\n",
        "> - Represents: A secondary proxy for workout intensity and daily activity level. This is a better variable for comparing the two datasets, as it's measured the same way.\n",
        "> - Transformations: None needed.\n",
        "> - Different from initial thoughts?: No, this is as expected.\n",
        "> - Missing Data or Outliers: No missing values in either cleaned dataset.\n",
        "\n",
        "> Descriptive Statistics:\n",
        "> - Apple: The mean is 9090 steps.\n",
        "> - Fitbit: The mean is 6546 steps. This indicates my personal data comes from a (on average) more active individual than the average of the Fitbit user pool.\n",
        "\n",
        "> Distribution & Visuals:\n",
        "> - The TotalSteps_distributions.png plot shows the two distributions.\n",
        "> - Apple (green): Right-skewed, with a large peak around 10,000-12,000 steps.\n",
        "> - Fitbit (lime): Also right-skewed, but the main peak is lower, around 6,000-8,000 steps. This confirms the finding from the descriptive statistics.\n",
        "\n",
        "Variable 4: TotalMinutesAsleep (Confounding Variable)\n",
        "> - Datatype: int64 (Apple) and float64 (Fitbit).\n",
        "> - Units: Minutes.\n",
        "> - Represents: A key confounding variable. Lack of sleep can raise RHR, independently of exercise.\n",
        "> - Transformations: None needed.\n",
        "> - Different from initial thoughts?: No.\n",
        "> - Missing Data or Outliers:\n",
        "> - Apple: No missing data.\n",
        "> - Fitbit: Had NaN values from the merge, which were handled in Project 2.\n",
        "\n",
        "> Handling: The NaN values in the Fitbit data were imputed using the user-specific median.\n",
        "\n",
        "> Descriptive Statistics:\n",
        "> - Apple: The mean is 446 minutes (~7.4 hours) with a large range (min 0, max 1404). The 0-minute days are likely days the watch wasn't worn to sleep, but I will leave them as they are not physiologically impossible (unlike a 0 RHR).\n",
        "> - Fitbit: The mean is 460 minutes (~7.7 hours).\n",
        "\n",
        "> Distribution & Visuals:\n",
        "> - The TotalMinutesAsleep_distributions.png plot shows the two distributions.\n",
        "> - Apple (purple): Roughly normal distribution centered around 450 minutes, but with a tail of low-sleep days.\n",
        "> - Fitbit (magenta): A very tight, normal distribution, also centered around 450 minutes. This data appears cleaner, likely due to the imputations smoothing it out."
      ],
      "metadata": {
        "id": "scGB47mI_oG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####6. Explore Relationships Between Variables\n",
        "> This is the core of my hypothesis. I'll check for correlations, pairwise relationships, and time-based (periodicity) patterns."
      ],
      "metadata": {
        "id": "FPuL6Cna5ccf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####6a. Scatter Plots (Direct Hypothesis Test)\n",
        "> First, I'll plot my primary independent variable (Calories) against my dependent variable (RestingHeartRate) for both datasets."
      ],
      "metadata": {
        "id": "NWJDL_BZ5gHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relationship Scatter Plot for Apple Data\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.regplot(x='ActiveCalories', y='RestingHeartRate', data=df_apple_final, scatter_kws={'alpha':0.5})\n",
        "plt.title('Workout Intensity vs. Resting Heart Rate (Apple Data)')\n",
        "plt.xlabel('Active Calories Burned')\n",
        "plt.ylabel('Resting Heart Rate (bpm)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Relationship Scatter Plot for Fitbit Data\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.regplot(x='Calories', y='RestingHeartRate', data=df_fitbit_final, scatter_kws={'alpha':0.5})\n",
        "plt.title('Workout Intensity vs. Resting Heart Rate (Fitbit Data)')\n",
        "plt.xlabel('Total Calories Burned')\n",
        "plt.ylabel('Resting Heart Rate (bpm)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ulsyR-B45cHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Analysis (Scatter Plots):\n",
        "\n",
        "- Apple Data: The regression line shows a clear negative correlation between ActiveCalories and RestingHeartRate. As my daily active calories go up, my RHR tends to go down. This provides the first piece of visual evidence supporting my alternate hypothesis. The data is noisy, but the trend is visible.\n",
        "\n",
        "- Fitbit Data: The trend is also negative but appears much weaker (flatter). This could be because 'Total Calories' is a poor proxy for intensity, or because the effect is being washed out by aggregating 35 different people (an example of Simpson's Paradox, which I'll look at later)."
      ],
      "metadata": {
        "id": "f0qgAuOx5nCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####6b. Correlation Matrix\n",
        ">A scatter plot is good for two variables, but a correlation heatmap gives a quick overview of all linear relationships in the data."
      ],
      "metadata": {
        "id": "YmjUdwiI57Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Apple Data Correlations ---\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "# We must drop the 'Date' column as corr() only works on numeric data\n",
        "sns.heatmap(df_apple_final.drop('Date', axis=1).corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix (Apple Data)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Fitbit Data Correlations ---\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Drop non-numeric 'Date' and user 'Id' for the correlation\n",
        "df_fitbit_corr = df_fitbit_final.drop(['Date', 'Id'], axis=1).rename(columns={'Calories': 'TotalCalories'})\n",
        "sns.heatmap(df_fitbit_corr.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix (Fitbit Data)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o4aLQ2ru53YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Analysis (Heatmaps):\n",
        "\n",
        "> Apple Data:\n",
        ">  - RestingHeartRate vs. ActiveCalories: -0.22. This confirms the slight negative correlation from the scatter plot.\n",
        "> - RestingHeartRate vs. TotalSteps: -0.21. A very similar strength, suggesting both are decent proxies for intensity.\n",
        "> - RestingHeartRate vs. TotalMinutesAsleep: -0.12. A weaker, but still negative, relationship.\n",
        "\n",
        ">Fitbit Data:\n",
        "> - RestingHeartRate vs. TotalCalories: -0.12. A very weak negative correlation, confirming the flat scatter plot.\n",
        "> - RestingHeartRate vs. TotalSteps: -0.23. This is a much stronger relationship, suggesting TotalSteps is a better predictor of RHR than TotalCalories in this dataset.\n",
        "> - RestingHeartRate vs. TotalMinutesAsleep: -0.26. This is the strongest correlation with RHR in the Fitbit set, highlighting the importance of sleep as a key variable."
      ],
      "metadata": {
        "id": "hyMYH-WN5m9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####6c. Time Series Analysis (Periodicity)\n",
        "> Finally, I'll look for patterns over time. The Fitbit data is only for one month, but my Apple data spans two years, which is perfect for seeing long-term trends."
      ],
      "metadata": {
        "id": "0lK4A-6n5m6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time Series Plot for Apple Data\n",
        "# Ensuring the 'Date' column is in datetime format\n",
        "df_apple_final['Date'] = pd.to_datetime(df_apple_final['Date'])\n",
        "\n",
        "# Sort by date to ensure the plot is correct\n",
        "df_apple_final_sorted = df_apple_final.sort_values('Date')\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "# Plot the 30-day rolling average to see the long-term trend\n",
        "plt.plot(df_apple_final_sorted['Date'], df_apple_final_sorted['RestingHeartRate'].rolling(window=30).mean(), label='30-Day Rolling Average')\n",
        "plt.title('Long-Term Resting Heart Rate Trend (Apple Data)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average Resting Heart Rate (bpm)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IzWgxYVz6fJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Time Series Plot for Fitbit Data\n",
        "# Ensure the 'Date' column is in datetime format\n",
        "df_fitbit_final['Date'] = pd.to_datetime(df_fitbit_final['Date'])\n",
        "\n",
        "# Calculate the average resting heart rate across all users for each day\n",
        "df_fitbit_daily_avg = df_fitbit_final.groupby('Date')['RestingHeartRate'].mean().reset_index()\n",
        "\n",
        "# Sort by date\n",
        "df_fitbit_daily_avg_sorted = df_fitbit_daily_avg.sort_values('Date')\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "# Plot the daily average and a 5-day rolling average to see the short-term trend\n",
        "plt.plot(df_fitbit_daily_avg_sorted['Date'], df_fitbit_daily_avg_sorted['RestingHeartRate'], label='Daily Average RHR', alpha=0.5)\n",
        "plt.plot(df_fitbit_daily_avg_sorted['Date'], df_fitbit_daily_avg_sorted['RestingHeartRate'].rolling(window=5).mean(), label='5-Day Rolling Average', linewidth=2)\n",
        "plt.title('Short-Term Resting Heart Rate Trend (Fitbit Data - Averaged Across All Users)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average Resting Heart Rate (bpm)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HuLtRVWJ6i9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Analysis (Time Series):\n",
        "\n",
        "> **Apple Data (30-day Rolling Avg):** This plot is the most compelling evidence so far. My average RHR shows a clear and significant downward trend over the two-year period, starting from an average of ~65 bpm in late 2023 and decreasing to around ~58 bpm by late 2025. This strongly suggests a long-term improvement in cardiovascular fitness, which directly supports my hypothesis that consistent activity (tracked by calories/steps) leads to a lower RHR.\n",
        "\n",
        "> **Fitbit Data (5-day Rolling Avg):** This plot shows the daily average RHR for all users over one month. There is a lot of daily fluctuation, but the rolling average oscillates between 55-58 bpm without a clear upward or downward trend. This is expected for such a short, aggregated dataset."
      ],
      "metadata": {
        "id": "CF7Nc_nn5m3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####6d. Simpson's Paradox (Optional Extra Credit)\n",
        "> In my initial analysis (Section 6a), I noted that the RHR vs. Calories scatter plot for the aggregated Fitbit data showed a very weak trend. I suspected this might be an example of Simpson's Paradox, where the trend for the total group is different from the trends for the subgroups (in this case, the individual users)\n",
        "\n",
        "> Let's test this by plotting the relationship between TotalSteps and RestingHeartRate but using color to separate each of the 35 users."
      ],
      "metadata": {
        "id": "aGhomYnK9Mo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "\n",
        "#googled on how to use altair chart and reused the code from stack overflow\n",
        "\n",
        "# We need to make sure the User ID is treated as a category ('nominal'), not a number.\n",
        "# Using .copy() to avoid SettingWithCopyWarning\n",
        "df_fitbit_final_altair = df_fitbit_final.copy()\n",
        "df_fitbit_final_altair['Id_str'] = df_fitbit_final_altair['Id'].astype(str)\n",
        "\n",
        "# Create the scatter plot using Altair\n",
        "chart = alt.Chart(df_fitbit_final_altair).mark_circle(opacity=0.8).encode(\n",
        "    # Use TotalSteps and RestingHeartRate on the axes\n",
        "    x=alt.X('TotalSteps', title='Total Steps per Day', scale=alt.Scale(zero=False)),\n",
        "    y=alt.Y('RestingHeartRate', title='Resting Heart Rate (bpm)', scale=alt.Scale(zero=False)),\n",
        "\n",
        "    # Color each dot by the unique User ID\n",
        "    color=alt.Color('Id_str', title=\"User ID\", legend=None),\n",
        "\n",
        "    # Add tooltips to see the user ID and values on hover\n",
        "    tooltip=['Id_str', 'TotalSteps', 'RestingHeartRate']\n",
        ").properties(\n",
        "    title='RHR vs. Total Steps (Subgroups per User)'\n",
        ").interactive() # Make the chart zoomable and pannable\n",
        "\n",
        "chart"
      ],
      "metadata": {
        "id": "kxjBVTQO9XJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Analysis (Simpson's Paradox Plot):\n",
        "\n",
        "> This plot clearly demonstrates Simpson's Paradox.\n",
        "> - Aggregated Trend: If you were to draw one single regression line through all the points (like in my previous scatter plot in 6a), the trend would be very flat and weak.\n",
        "> - Subgroup Trends: By looking at the individual colored clusters (each representing one person), we can see many strong negative trends. For example, the light-blue user (top-left) shows a clear drop in RHR on days they have more steps. The same is true for the dark-red user (bottom-middle) and many others.\n",
        "\n",
        "> Conclusion: The weak correlation in the aggregated data is misleading. It masks the stronger negative correlation that exists for many of the individuals within the dataset. This confirms my hypothesis is likely true for individuals, but that relationship is lost when you combine them all without accounting for their different baseline fitness levels."
      ],
      "metadata": {
        "id": "LsJxG8579aii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####7. Do You Trust This Data?\n",
        "Yes, I trust this data for this analysis, with some caveats.\n",
        "\n",
        ">Apple Data: This is my own personal data, so I trust its source completely. The cleaning I did (removing one impossible 0 RHR value) makes it reliable. The trends (skewed activity, long-term RHR improvement) align perfectly with my personal experience.\n",
        "\n",
        ">Fitbit Data: This is a reliable public dataset, but its usefulness is limited by two factors I discovered during exploration:\n",
        "> - The Calories variable is a poor proxy for intensity. TotalSteps is better.\n",
        "> - The data aggregates 35 users. The multi-modal RHR distribution and weak correlations suggest that per-user trends are being hidden by this aggregation (Simpson's Paradox).\n",
        "\n",
        "Handling: I will proceed using both datasets, but I will prioritize the findings from my personal data as the primary source for testing my hypothesis. I'll use the Fitbit data as a general, (and weaker) point of comparison."
      ],
      "metadata": {
        "id": "mGghNkyR5mj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####8. Wrap Up\n",
        ">Overview of What I Learned: The exploration process confirmed that my data is clean and usable. The most important insight was discovering the difference between my longitudinal (Apple) data and the cross-sectional, aggregated (Fitbit) data. The distributions and correlations were very different, highlighting how data is aggregated is just as important as what is collected.\n",
        "\n",
        ">Did this affect your hypothesis? My alternate hypothesis (Increased workout intensity... is associated with a decrease in resting heart rate over time) is strongly supported by this exploration.\n",
        "> - The Apple data showed a negative correlation (-0.22) between ActiveCalories and RestingHeartRate.\n",
        "> - The Apple time series plot showed a clear long-term decrease in my RHR over two years.\n",
        "> - The Fitbit data also showed weak-to-moderate negative correlations between RHR and both TotalSteps (-0.23) and TotalMinutesAsleep (-0.26).\n",
        "\n",
        "> Summarize Key Findings:\n",
        "> - Finding 1: The relationship between exercise and RHR is present but noisy in day-to-day data. The long-term trend is much clearer.\n",
        "> - Finding 2: TotalSteps appears to be a more stable predictor for RHR than TotalCalories when comparing aggregated data.\n",
        "> - Finding 3: Sleep (TotalMinutesAsleep) has a significant negative correlation with RHR and must be included in my model as a key confounder."
      ],
      "metadata": {
        "id": "zC03uc9y7Q1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Project 4 : Analysis, Hypothesis Testing, and ML**\n"
      ],
      "metadata": {
        "id": "-R5jAuhE3q8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Modeling Strategy**\n",
        "To test my hypothesis, I'll implement two different Machine Learning Algorithms:\n",
        "1.  **Linear Regression:** This serves as my baseline. It assumes a straight-line relationship between activity and heart rate. It will help me see the direct positive or negative correlation of each variable.\n",
        "2.  **Random Forest Regressor:** This is a more complex, non-linear model. I am using it to capture interactions between variables (e.g., how sleep quality might amplify the benefits of exercise) that a simple linear model might miss."
      ],
      "metadata": {
        "id": "xtGOZVfUTZPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**2. What kind of ML task is presented by your hypothesis, and what type of learning is it?**\n",
        "\n",
        "> **ML Task:** The hypothesis presents a Regression task. Learning Type: This is Supervised Learning.\n",
        "\n",
        "> **Description:** I intend to build a regression model to predict the daily RestingHeartRate (target variable) based on workout intensity and volume metrics. Since the target variable is continuous (bpm), regression is the appropriate task. The model will be trained on labeled data where the input features (activity metrics) and the output (RHR) are known, making it a supervised learning problem."
      ],
      "metadata": {
        "id": "xrRIwfa53uF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**3. What features will you use?**\n",
        "\n",
        "**Features to Use:**\n",
        "> Target (Label): RestingHeartRate\n",
        "\n",
        ">Predictors (Features):\n",
        "> - ActiveCalories (Apple) / Calories (Fitbit): Primary measure of workout intensity.\n",
        "> - TotalSteps: Secondary measure of daily activity volume.\n",
        "> - TotalMinutesAsleep: Key confounding variable to control for recovery and sleep quality.\n",
        "> - Date (processed): Will be engineered into numeric features (e.g., ordinal or time-since-start) to capture the long-term trend observed in the time-series analysis.\n",
        "\n",
        "\n",
        "**Feature Engineering:**\n",
        "\n",
        "> Date Transformation: The Date column is currently a datetime object, which most regression algorithms cannot handle directly. I will convert it to an ordinal number or \"Days Since Start\" to allow the model to learn the time-dependent downward trend in RHR.\n",
        "\n",
        "> Scaling/Normalization: Since features like TotalSteps (thousands) and TotalMinutesAsleep (hundreds) have vastly different scales, I will apply standard scaling (z-score normalization) to ensure the algorithm treats them equally.\n",
        "\n",
        "> Dimensionality Reduction:\n",
        "> - Reduction: I will likely not apply PCA or heavy dimensionality reduction because I only have 3-4 core features. Reducing dimensions further might lose interpretability, which is key for my hypothesis (I need to know which specific factor drives RHR).\n",
        "> - Resulting Dimensionality: The final dataset will have 3 predictor columns: ActiveCalories, TotalSteps, TotalMinutesAsleep, plus the transformed Date feature.\n",
        "\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "> The resulting dataset assumes that the relationship between activity and RHR is roughly linear (or can be approximated as such).\n",
        "\n",
        "> Independence: We assume daily observations are independent (though time-series data violates this, we will treat it as independent samples for this basic regression task).\n",
        "\n",
        "\n",
        "**Selected Features Type:**\n",
        "\n",
        "> - ActiveCalories: Continuous\n",
        "> - TotalSteps: Continuous (discrete count, treated as continuous)\n",
        "> - TotalMinutesAsleep: Continuous\n",
        "> - Date (transformed): Continuous"
      ],
      "metadata": {
        "id": "0C-HFQLO4dv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**4. Algorithm Selection**\n",
        "\n",
        "**Algorithm: Linear Regression (or optionally Random Forest Regressor for comparison).**\n",
        "\n",
        "\n",
        "**Why this algorithm?**\n",
        "\n",
        "> - Linear Regression is the simplest and most interpretable algorithm for testing the relationship between continuous variables. It directly provides coefficients that tell us how much RHR decreases for every unit increase in calories or sleep, which perfectly answers the hypothesis.\n",
        "> - Since the scatter plots in Project 3 showed a linear-looking negative trend, a linear model is a strong candidate.\n",
        "\n",
        "\n",
        "**Assumptions of Linear Regression:**\n",
        "\n",
        "> - Linearity: The relationship between X and Y is linear.\n",
        "> - Normality: The residuals (errors) should be normally distributed.\n",
        "> - Homoscedasticity: The variance of error terms should be constant.\n",
        "> - No Multicollinearity: Features should not be highly correlated with each other (I will check the correlation between Steps and Calories).\n",
        "\n",
        "\n",
        "**Known Issues & Mitigations:**\n",
        "\n",
        "> - Outliers: Linear regression is sensitive to outliers. I have already cleaned 0 RHR values, but I will double-check for extreme calorie counts.\n",
        "> - Multicollinearity: Steps and Calories are likely correlated. If the correlation is too high (>0.8), I may drop one or use Ridge/Lasso regression (regularization) to mitigate this."
      ],
      "metadata": {
        "id": "u5AaQ3we5a_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**5. Hyperparameter Selection**\n",
        "\n",
        "**For Linear Regression:**\n",
        "\n",
        "> - There are usually no hyperparameters to tune for standard Least Squares Linear Regression.\n",
        "> - If using Ridge/Lasso (to handle multicollinearity): The hyperparameter is alpha (regularization strength). I would choose it using cross-validation or a simple grid search (e.g., trying alpha = 0.1, 1.0, 10.0).\n",
        "\n",
        "**For Random Forest (if used as alternate):**\n",
        "> - n_estimators (number of trees): I would start with 100.\n",
        "> - max_depth: To prevent overfitting, I might limit this to 5 or 10."
      ],
      "metadata": {
        "id": "XZcLslYq6his"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**6. Post-processing**\n",
        "\n",
        "**Techniques:**\n",
        "\n",
        "> - Residual Analysis: After training, I will plot the residuals (predicted vs. actual values) to check for patterns. If residuals are random, the model is good. If there's a pattern (e.g., a curve), a linear model might be insufficient.\n",
        "> - De-scaling: If I predict values using scaled data, I will need to inverse-transform the predictions to get the actual heart rate (bpm) for readability.\n",
        "\n",
        "\n",
        "**Why?**\n",
        "\n",
        "> - To validate that the model's assumptions were met and to present the results in understandable units (bpm) rather than standardized z-scores."
      ],
      "metadata": {
        "id": "IcHWoUTV67Rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**7. ML Code Implementation**\n",
        "**Steps to Code:**\n",
        "1. Data Splitting: Split the cleaned Apple dataset (and Fitbit dataset separately) into Training (80%) and Testing (20%) sets using train_test_split.\n",
        "2. Preprocessing Pipeline: Apply StandardScaler to the features.\n",
        "3. Train: Fit the LinearRegression model on the training set.\n",
        "4. Predict: Generate predictions on the test set.\n",
        "5. Evaluate: Calculate and print the Accuracy (for regression, I'll print $R^2$ score or Mean Squared Error)."
      ],
      "metadata": {
        "id": "lqmqLb8G7VHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime as dt\n",
        "\n",
        "# ==========================================\n",
        "# 2. ANALYSIS 1: APPLE HEALTH DATA (Longitudinal)\n",
        "# ==========================================\n",
        "print(\"--- ANALYSIS 1: APPLE HEALTH DATA ---\")\n",
        "\n",
        "# Setup Data\n",
        "df_ml_apple = df_apple_final.copy()\n",
        "# Drop rows with missing values\n",
        "df_ml_apple = df_ml_apple.dropna(subset=['RestingHeartRate', 'ActiveCalories', 'TotalSteps'])\n",
        "\n",
        "# Feature Engineering: Convert 'Date' (Capitalized) to ordinal\n",
        "df_ml_apple['Date_Ordinal'] = pd.to_datetime(df_ml_apple['Date']).map(dt.datetime.toordinal)\n",
        "\n",
        "# Define X and y\n",
        "# Added TotalSteps to features for better accuracy\n",
        "features_apple = ['ActiveCalories', 'TotalSteps', 'Date_Ordinal']\n",
        "target_apple = 'RestingHeartRate'\n",
        "\n",
        "X_a = df_ml_apple[features_apple]\n",
        "y_a = df_ml_apple[target_apple]\n",
        "\n",
        "# Split Data (80% Train, 20% Test)\n",
        "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale Data\n",
        "scaler_a = StandardScaler()\n",
        "X_train_a_scaled = scaler_a.fit_transform(X_train_a)\n",
        "X_test_a_scaled = scaler_a.transform(X_test_a)\n",
        "\n",
        "# --- Model A: Linear Regression ---\n",
        "lr_model_a = LinearRegression()\n",
        "lr_model_a.fit(X_train_a_scaled, y_train_a)\n",
        "y_pred_lr_a = lr_model_a.predict(X_test_a_scaled)\n",
        "r2_lr_a = r2_score(y_test_a, y_pred_lr_a)\n",
        "\n",
        "# --- Model B: Random Forest (Comparison) ---\n",
        "rf_model_a = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_a.fit(X_train_a_scaled, y_train_a)\n",
        "y_pred_rf_a = rf_model_a.predict(X_test_a_scaled)\n",
        "r2_rf_a = r2_score(y_test_a, y_pred_rf_a)\n",
        "\n",
        "# Output Results\n",
        "print(f\"Linear Regression RÂ²: {r2_lr_a:.4f}\")\n",
        "print(f\"Random Forest RÂ²:     {r2_rf_a:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "print(\"Coefficients (Linear Model):\")\n",
        "for f, c in zip(features_apple, lr_model_a.coef_):\n",
        "    print(f\"  {f}: {c:.4f}\")\n",
        "\n",
        "# Visualization: Actual vs Predicted (Linear Model)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(y_test_a, y_pred_lr_a, alpha=0.6, color='blue', label='Predictions')\n",
        "plt.plot([y_a.min(), y_a.max()], [y_a.min(), y_a.max()], 'r--', lw=2, label='Perfect Fit')\n",
        "plt.title(\"Apple Data: Actual vs Predicted RHR (Linear Regression)\")\n",
        "plt.xlabel(\"Actual RHR\")\n",
        "plt.ylabel(\"Predicted RHR\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. ANALYSIS 2: FITBIT DATA (Activity & Sleep)\n",
        "# ==========================================\n",
        "print(\"--- ANALYSIS 2: FITBIT DATA ---\")\n",
        "\n",
        "# Setup Data\n",
        "df_ml_fitbit = df_fitbit_final.copy()\n",
        "# Check for standard Fitbit column names\n",
        "# If you get a KeyError here, verify your Fitbit column names using df_fitbit_final.columns\n",
        "df_ml_fitbit = df_ml_fitbit.dropna(subset=['RestingHeartRate', 'TotalSteps', 'TotalMinutesAsleep', 'Calories'])\n",
        "\n",
        "# Define X and y\n",
        "features_fitbit = ['TotalSteps', 'TotalMinutesAsleep', 'Calories']\n",
        "target_fitbit = 'RestingHeartRate'\n",
        "\n",
        "X_f = df_ml_fitbit[features_fitbit]\n",
        "y_f = df_ml_fitbit[target_fitbit]\n",
        "\n",
        "# Split Data\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_f, y_f, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale Data\n",
        "scaler_f = StandardScaler()\n",
        "X_train_f_scaled = scaler_f.fit_transform(X_train_f)\n",
        "X_test_f_scaled = scaler_f.transform(X_test_f)\n",
        "\n",
        "# --- Model A: Linear Regression ---\n",
        "lr_model_f = LinearRegression()\n",
        "lr_model_f.fit(X_train_f_scaled, y_train_f)\n",
        "y_pred_lr_f = lr_model_f.predict(X_test_f_scaled)\n",
        "r2_lr_f = r2_score(y_test_f, y_pred_lr_f)\n",
        "\n",
        "# --- Model B: Random Forest (Comparison) ---\n",
        "rf_model_f = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_f.fit(X_train_f_scaled, y_train_f)\n",
        "y_pred_rf_f = rf_model_f.predict(X_test_f_scaled)\n",
        "r2_rf_f = r2_score(y_test_f, y_pred_rf_f)\n",
        "\n",
        "# Output Results\n",
        "print(f\"Linear Regression RÂ²: {r2_lr_f:.4f}\")\n",
        "print(f\"Random Forest RÂ²:     {r2_rf_f:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "print(\"Coefficients (Linear Model):\")\n",
        "for f, c in zip(features_fitbit, lr_model_f.coef_):\n",
        "    print(f\"  {f}: {c:.4f}\")\n",
        "\n",
        "# Visualization: Feature Importance (Random Forest)\n",
        "plt.figure(figsize=(8, 5))\n",
        "importances = rf_model_f.feature_importances_\n",
        "sns.barplot(x=importances, y=features_fitbit, palette='viridis')\n",
        "# sns.barplot(x=importances, y=features_fitbit, palette='hue')\n",
        "plt.title(\"Fitbit Data: Feature Importance (Random Forest)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rxE45hgi_MmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Model Interpretation & Conclusion**\n",
        "\n",
        "**Comparison of Models:**\n",
        "\n",
        ">I ran both Linear Regression and Random Forest on my datasets.\n",
        "> - **Apple Data:** The Linear Regression model performed **Better** than Random Forest (**RÂ²: 0.20 vs 0.16**). This makes sense because the dominant factor in my Apple data was the simple linear trend of time (my RHR decreasing over 2 years). Random Forest sometimes overfits simple trends.\n",
        "> - **Fitbit Data:** The Random Forest model performed better here (**RÂ²: 0.17 vs 0.08**), likely because the relationship between daily sleep, steps, and heart rate is non-linear and complex.\n",
        "\n",
        "**Key Drivers (Coefficients):**\n",
        "\n",
        ">1. **Time/Date (Apple):** Had a coefficient of **-0.4772**, confirming my main hypothesis that my cardiovascular health has significantly improved over the long term.\n",
        "\n",
        ">2. **Active Calories:** Results were mixed.\n",
        "     - In the **Apple** model, this was positive (+1.37), suggesting that on days of high exertion, my RHR might be slightly elevated due to recovery stress.\n",
        "     - In the **Fitbit** model, Calories had a negative coefficient (**-0.58**), supporting the idea that higher activity generally relates to better heart health.\n",
        "\n",
        ">3. **Sleep (Fitbit):** The model confirmed that lack of sleep is a major factor. The coefficient was **-1.16**, meaning more minutes of sleep strongly correlates with a lower (better) resting heart rate.\n",
        "\n",
        "**Final Verdict:**\n",
        ">While the day-to-day prediction is noisy, the **Linear Regression** model successfully captured the general downward trend in my Resting Heart Rate over time, and the **Fitbit** analysis highlighted the critical importance of Sleep for daily recovery."
      ],
      "metadata": {
        "id": "d5pJpajUDGZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "###Project 5 : Model Evaluation, Insights & Policy Decision"
      ],
      "metadata": {
        "id": "br07xneVm8yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**2. Evaluate Machine Learning Alogorithm**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BrGwBMySm98Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What metrics will most effectively measure the performance of your model? Why?**\n",
        "> Since the target variable, **Resting Heart Rate(RHR)**, is a continious numerical value, this is a Regression problem. The most effective metrics to evaluate performace are:\n",
        ">- R-squared : Why it's effective: This represents the \"Goodness of Fit\". It tells us what percentage of the variation in my daily heart rate is explained purely by my activity and sleep data. For health data, which is very noisy, an $R^2$ even around 0.20-0.30 is meaningful. It allows us to see if the model is finding any signal amidst the noise.\n",
        ">- Mean Absolute Error(MAE): Why it's effective: This is the most interpretable metric for a non-technical audience. If the MAE is 2.5, it means \"On any given day, the model's prediction is typically off by about 2.5 beats per minute.\" This helps contextualize if the model is useful for daily tracking.\n",
        ">- Root Mean Squared Error (RMSE): Why it's effective: RMSE penalizes larger errors more heavily that MAE. In a health context, predicting a heart rate of 50 when it is actually 90 is a dangerous error. RMSE helps us identify if our model has many of these \"large misses\"."
      ],
      "metadata": {
        "id": "LIq7xGoWxXui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Model Comparison**"
      ],
      "metadata": {
        "id": "LC3YeK6Ly7tC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you need to compare these metrics across models? Why or why not?**\n",
        "\n",
        "> Yes, comparison is necessary\n",
        "> - Comparing Algorithms (Linear vs Random Forest): Comparing metrics helps determine if the relationship is linear(simple) or non-linear(complex). If Random Forest significantly outperforms Linear Regression, it provides the physiological relationships is non-linear.\n",
        "> - Comparing Data Sources (Apple vs. Fitbit): Comparing the Apple (Personal) metrics against the Fitbit (Population) metrics helps assess generalizability. It tells us if the model works better for a specific individual (customized) or if it can work for the general population."
      ],
      "metadata": {
        "id": "SjFvTBvcxhEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How will you do it?**\n",
        "\n",
        ">I will calculate $R^2$, MAE, and RMSE for all four model combinations (Apple Linear, Apple RF, Fitbit Linear, Fitbit RF) and print them side-by-side."
      ],
      "metadata": {
        "id": "p3-XaXOsy5U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_metrics(y_true, y_pred, model_name):\n",
        "  r2 = r2_score(y_true, y_pred)\n",
        "  mae = mean_absolute_error(y_true, y_pred)\n",
        "  rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "  return [model_name, r2, mae, rmse]\n",
        "\n",
        "\n",
        "# Gather metrics for all existing models\n",
        "metrics_data = []\n",
        "metrics_data.append(get_metrics(y_test_a, y_pred_lr_a, \"Apple Linear Reg\"))\n",
        "metrics_data.append(get_metrics(y_test_a, y_pred_rf_a, \"Apple Random Forest\"))\n",
        "metrics_data.append(get_metrics(y_test_f, y_pred_lr_f, \"Fitbit Linear Reg\"))\n",
        "metrics_data.append(get_metrics(y_test_f, y_pred_rf_f, \"Fitbit Random Forest\"))\n",
        "\n",
        "\n",
        "# Create a DataFrame for nice display\n",
        "df_metrics = pd.DataFrame(metrics_data, columns=[\"Model\", \"R2 Score\", \"MAE\", \"RMSE\"])\n",
        "print(df_metrics)"
      ],
      "metadata": {
        "id": "nWUuJbZ3zMj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizations**\n",
        "\n",
        "**Show/visualize the performance metric(s).**\n",
        "\n",
        ">I will visualize the Predicted vs. Actual values for the best performing model. A perfect model would show points lying exactly on the diagonal red line."
      ],
      "metadata": {
        "id": "MfAwooNF0aU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualization for Apple Linear Regression\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_test_a, y=y_pred_lr_a, alpha=0.6, color='blue', label='Daily Data Points')\n",
        "\n",
        "# Plotting the \"Perfect Fit\" line\n",
        "m, b = np.polyfit(y_test_a, y_pred_lr_a, 1)\n",
        "plt.plot(y_test_a, m*y_test_a + b, color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Actual Resting Heart Rate\")\n",
        "plt.ylabel(\"Predicted Resting Heart Rate\")\n",
        "plt.title(\"Evaluation of Fit: Actual vs Predicted (Apple Data)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oR8xTKTN0UHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visual Analysis:**\n",
        "The scatter plot above visualizes the model's accuracy.\n",
        "* The **Red Line** represents a perfect prediction.\n",
        "* The **Blue Dots** are the actual days.\n",
        "* **Observation:** The spread of dots around the line confirms that while the model captures the general range of my heart rate, there is significant variance (noise) that steps and calories alone cannot explain."
      ],
      "metadata": {
        "id": "eOrTJDpzVC47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Fit**\n",
        "\n",
        "**Are you overfitting? Underfitting? Fitting well? How do you know?**\n",
        "\n",
        "> Conclusion: The models are likely **Underfitting**\n",
        "\n",
        ">How did i come to this conclusion:\n",
        "> 1. Low $R^2$ Scores: The $R^2$ scores are relatively low (e.g., 0.08 - 0.30). A model that fits well would typically have an $R^2$ above 0.50 or 0.60.\n",
        "> 2. No \"High Train/Low Test\" Gap: Overfitting usually presents as a very high score on training data (e.g., $R^2 = 0.95$) and a very low score on testing data. Since the performance is low across the board, the model is failing to capture the complexity of the data (High Bias), which is the definition of Underfitting.\n",
        "> 3. Missing Variables: Heart rate is affected by stress, hydration, genetics, and dietâvariables not present in this dataset. The model cannot \"fit\" what it cannot see."
      ],
      "metadata": {
        "id": "Ec1f2iGv1XRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternative Algorithms (Extra Credit)**\n",
        "\n",
        "**Is there a different ML algorithm or tweak to the existing one that could be as good or better? Why?**\n",
        "\n",
        "> Yes, there are different algorithms which I could use.\n",
        "> 1. Ridge Regression: This introduces **regularization**. Since \"Steps\" and \"Calories\" are often highly correlated (multicollinearity), standard Linear Regression can become unstable. Ridge handles this by penalizing large cofficients.\n",
        "> 2. Gradient Boosting (XGBoost/GBR): Unlike random forest, which builds independent trees, Gradient Boosting builds trees sequentially, where each new tree specifically tries to fix the errors of the previous one. This is often superior for tabular data with subtle patterns.\n",
        "> 3. Support Vector Regression(SVR): SVR works well for finding a \"margin of tolerance\" around the data, which might be robust against the nosiy daily fluctuations of heart rate data.\n"
      ],
      "metadata": {
        "id": "vmryTVEd2euV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scaling is required for SVR and Ridge\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_a)\n",
        "X_test_scaled = scaler.transform(X_test_a)\n",
        "\n",
        "# --- Algorithm 1: Ridge Regression ---\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train_scaled, y_train_a)\n",
        "y_pred_ridge = ridge.predict(X_test_scaled)\n",
        "\n",
        "# --- Algorithm 2: Gradient Boosting Regressor ---\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gbr.fit(X_train_scaled, y_train_a)\n",
        "y_pred_gbr = gbr.predict(X_test_scaled)\n",
        "\n",
        "# --- Algorithm 3: Support Vector Regression (SVR) ---\n",
        "svr = SVR(kernel='rbf', C=10, gamma='scale')\n",
        "svr.fit(X_train_scaled, y_train_a)\n",
        "y_pred_svr = svr.predict(X_test_scaled)\n",
        "\n",
        "# Collect metrics for the new models\n",
        "ec_metrics = []\n",
        "ec_metrics.append(get_metrics(y_test_a, y_pred_ridge, \"Extra: Ridge Reg\"))\n",
        "ec_metrics.append(get_metrics(y_test_a, y_pred_gbr, \"Extra: Gradient Boosting\"))\n",
        "ec_metrics.append(get_metrics(y_test_a, y_pred_svr, \"Extra: SVR\"))\n",
        "\n",
        "# Combine with baseline for final comparison\n",
        "df_ec = pd.DataFrame(ec_metrics, columns=[\"Model\", \"R2 Score\", \"MAE\", \"RMSE\"])\n",
        "print(\"--- EXTRA CREDIT ALGORITHM COMPARISON ---\")\n",
        "print(df_ec)\n"
      ],
      "metadata": {
        "id": "2fyRenqS3cjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation of Metrics**\n",
        "\n",
        "* **R-squared (~0.20 - 0.26):** The scores indicate a weak-to-moderate correlation. This is expected in biological data, as Resting Heart Rate is influenced by many unmeasured factors like diet, hydration, and stress. The model captures the *trend* but not every daily fluctuation.\n",
        "* **RMSE (~4.0 bpm):** An average error of about 4 beats per minute is acceptable for a consumer health context. It means the model is generally accurate enough to distinguish between a \"healthy/recovered\" day and a \"stressed/fatigued\" day."
      ],
      "metadata": {
        "id": "18FtRJQaW70d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does the other algorithm/tweak compare for the metrics you care about?**\n",
        "\n",
        ">Based on the evaluation metrics from the new algorithms, here is how they compare:\n",
        "\n",
        "> **1. Gradient Boosting:**\n",
        "> - Observation: Gradient Boosting achieved the highest $R^2$ Score (0.2633) and the lowest RMSE (4.71) of all the models tested.\n",
        "> - Why it helps: Unlike Random Forest, which builds trees independently, Gradient Boosting builds trees sequentially to specifically correct the errors of the previous tree. This allowed it to better capture the subtle, non-linear patterns in the daily recovery data that the other models missed. It effectively squeezed the most \"signal\" out of the noisy health data.\n",
        "\n",
        "> **2. Ridge Regression (The Stability Check):**\n",
        "> - Observation:  The $R^2$ (0.2067) and RMSE (4.90) are nearly identical to the baseline Linear Regression model.\n",
        "> - Why it matters: This indicates that \"multicollinearity\" (overlap between Steps and Calories) was not a major issue in the dataset. If it were, Ridge would have significantly outperformed standard Linear Regression. Since it didn't, we know the simple linear model was already stable.\n",
        "\n",
        "> **3. Support Vector Regression (SVR):**\n",
        "> - Observations: SVR performed the worst of the group, with the lowest $R^2$ (0.1899).\n",
        "> - Why it failed: SVR Attempts to fit a strict \"margin\" around the data points. Because daily Resting Heart Rate is highly volatile (noisy) due to external factors like stress or diet, SVR struggled to find a consistent margin, resulting in a poorer fit than the tree-based models.\n",
        "\n",
        "\n",
        "**Conclusion:** Gradient Boosting is the superior algorithm for this specific shysiological dataset, providing a ~6% improvement in explanatory power ($R^2$) over the baseline linear approaches."
      ],
      "metadata": {
        "id": "oNQYGC5c51By"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**3. Insights**"
      ],
      "metadata": {
        "id": "1zWozlqK9kNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis Findings**\n",
        "\n",
        "**What did you find in terms of your hypothesis?**\n",
        "> **Hypothesis**: \"Increased physical activity leads to improvement in cardiovascular health (lower RHR) over time.\"\n",
        "\n",
        "> **Findings**: The hypothesis was **Partially Confirmed**, but with important nuances:\n",
        "\n",
        "> **1. Long-Term Trend (Confirmed)**: The Apple (Personal) Linear Regression model showed a significant negative coefficient for the Date variable (-0.4772). This confirms that consistent activity over a long period correlates with a lower resting heart rate.\n",
        "\n",
        "> **2. Daily Intensity (Mixed/Rejected)**: The relationships between *daily* activity and *next-day* RHR was not straightforward.\n",
        "> - In the **Fitbit(Population)** data, higher calories correlated with lower RHR(coefficient **-0.58**), supporting the hypothesis.\n",
        "> - However, in the **Apple** data, **Active Calories** had a positive coefficient(+1.37), suggesting that very high intensity days might temporarily raise RHR due to recovery demands.\n"
      ],
      "metadata": {
        "id": "M9-ZrmRf9oCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assumptions & Adjustments**\n",
        "\n",
        "**Any previous assumptions that you had to adjust, or proved wrong?**\n",
        "\n",
        "> **Assumption:** I assumed that a \"hard workout today\" would gurrantee a \"lower heart rate tomorrow\"\n",
        "\n",
        "> **Adjustments:** I had to adjust this view. The positive correlation of calories in my personal data suggests that RHR is also a **measure of stress/recovery. A hard workout imposes acute physiological stress, which keeps the heart rate elevated while the body repairs itself. I learned that \"health improvement\" is a long-term adaptation, not an immediate daily reward."
      ],
      "metadata": {
        "id": "KhS57ou__WVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is the problem different from what you had originally thought?**\n",
        "\n",
        "> **Yes**,  I originally thought this was simple \"Input(Exercise) -> Output (Health)\" problem.\n",
        "\n",
        "> **Realization**: I now see it as a multivariate control problem where sleep is just as critical as exercise. The fitbit model showed **TotalMinutesAsleep (coefficient -1.16)** was the strongest driver of low RHR. The problem is not just \"how much did I run?\" but \"did I sleep enough to recover from the run?\""
      ],
      "metadata": {
        "id": "d_n0ie2mAW-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Future Improvements**\n",
        "\n",
        "**Anything you would do differently if you were to do it again?**\n",
        "> **1. Feature Engineering (Time-Lags):** Instead of comparing Today's Steps to Today's RHR, I would create lagged features (e.g., \"Steps_Yesterday\", \"Avg_Steps_Last_Week\"). Physiological adaptations take time, and a rolling average would likely smooth out the noise and improve the $R^2$ score.\n",
        "\n",
        "> **2. Personalised Modeling for Fitbit:** Instead of aggregating 35 different users into one \"blob\" of data (Which led to a low $R^2$ of ~0.17), I would build individual regression models for each user ID or use a Mixed-Effects Model. This would account for the fact that every person has a differnt baseline heart rate."
      ],
      "metadata": {
        "id": "O5FJ-F8IBlYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Policy & Ethical Implications**\n",
        "\n",
        "**Are there any policy or other decisions that could be influenced by an analysis like yours?\n",
        "What are they, and what could be the wider effects?**\n",
        "\n",
        "> **Corporate Wellness Programs:** Currently, many companies run \"Step Count Challenges.\" My analysis suggests this is incomplete.\n",
        "> - New Policy: Companies should incentivize **Rest & Recovery** (e.g., \"7 Hours of Sleep Challenge\").\n",
        "> - Wider Effect: Prioritizing sleep over just \"movement volume\" could reduce employee burnout, improve cognitive function, and lower long-term healthcare costs more effectively than steps alone.\n",
        "\n",
        "> **Athletic Training Decisions:** Coaches often push for maximum volume.\n",
        "> - New decision: Use RHR data to **regulate training load**. If RHR spikes (as seen in my apple data), the athlete should rest, not just train harder. This prevents overtraining injuries.\n"
      ],
      "metadata": {
        "id": "-8NHyaRrCoBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What ethical concerns should you or someone reading your project consider?**\n",
        "\n",
        "> **1. Data Privacy and Re-identification:** The fitbit dataset contains granular minute-by-minute health data. Even if \"anonymized\", combining this with location data or other public leaks could re-identify specific individuals, revealing sensitive health conditions.\n",
        "\n",
        "> **2. Algorithmic bias (Insurance):** If health insurance companies used models like this to set premiums, they might unfairly penalize people with naturally higher heart rates or those with stressful jobs (which raises RHR), even if they are physically active.\n",
        "\n",
        "> **3. Data Ownership:** Who owns the biological data generated by the watch? The user, Apple/Google, or the employer paying for the wellness program? If the data suggests a health risk, does the platform have a duty to warn the user?"
      ],
      "metadata": {
        "id": "mOsb7U_cExmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Thoughts**\n",
        "**Final thoughts: Summarize your experience across all 5 projects. What did you learn?**\n",
        "\n",
        "> **Project 1 and 2 (Data Cleaning):** I learned that real-world data is messy. Cleaning dates, merging datasets, and handling missing values took 80% of the effort, but without it, the analysis would be impossible.\n",
        "\n",
        "> **Project 3 and 4 (Modeling):** I learned that \"more complex\" isn't always \"better,\" but sometimes it is necessary. Comparing Linear Regression to Random Forest showed me that human health data is often non-linear.\n",
        "\n",
        "> **Project 5 (Evaluation):** I learned that a low $R^2$ isn't a failureâit's a finding. It tells us that the system we are studying (the human body) is complex and influenced by variables we didn't capture (like diet or genetics). Data Science is as much about understanding what you can't predict as what you can."
      ],
      "metadata": {
        "id": "BVJE1UqtLt7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Final Hypothesis Verdict**\n",
        "\n",
        "**Original Hypothesis:** \"Increased physical activity leads to improvement in cardiovascular health (lower RHR) over time.\"\n",
        "\n",
        "**Conclusion:** The data **partially supports** this hypothesis, but with a critical distinction between *long-term* and *short-term* effects.\n",
        "1.  **Confirmed (Long-Term):** The negative coefficient for the `Date` variable proves that maintaining an active lifestyle over months correlates with a gradual decrease in RHR.\n",
        "2.  **Refined (Short-Term):** On a daily basis, high-intensity activity (`Active Calories`) does *not* immediately lower RHR; in fact, it often raises it due to acute recovery stress.\n",
        "3.  **New Insight:** The analysis revealed that **Sleep** is a co-equal factor in improving heart health, a variable I had originally underestimated."
      ],
      "metadata": {
        "id": "YHoRqeufVKUN"
      }
    }
  ]
}